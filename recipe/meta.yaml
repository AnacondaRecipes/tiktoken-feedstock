{% set name = "tiktoken" %}
{% set version = "0.7.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/tiktoken-{{ version }}.tar.gz
  sha256: 1077266e949c24e0291f6c350433c6f0971365ece2b173a23bc3b9f9defef6b6


build:
  number: 1
  script:
    - cargo-bundle-licenses --format yaml --output THIRDPARTY.yml
    - {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation
  number: 0

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    #- cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - {{ compiler('cxx') }}
    #- {{ stdlib("c") }}
    - {{ compiler('rust') }}
    - cargo-bundle-licenses
  host:
    - python
    - pip
    - setuptools
    - setuptools-rust
    - wheel
  run:
    - python
    - libgcc-ng  # [linux]
    - regex >=2022.1.18
    - requests >=2.26.0

test:
  imports:
    - tiktoken
    - tiktoken_ext
  source_files:
    - tests/
  requires:
    - pip
    - pytest
    - hypothesis
  commands:
    - pip check
    - python -c "import tiktoken; enc = tiktoken.get_encoding('gpt2'); assert enc.encode('hello world') == [31373, 995]"
    - pytest tests --import-mode=append -vv

about:
  home: https://github.com/openai/tiktoken
  dev_url: https://github.com/openai/tiktoken
  doc_url: https://github.com/openai/tiktoken
  summary: tiktoken is a fast BPE tokeniser for use with OpenAI's models
  description: tiktoken is a fast BPE tokeniser for use with OpenAI's models.
  license: MIT
  license_family: MIT
  license_file:
    - LICENSE
    #- THIRDPARTY.yml

extra:
  anaconda-services:
    ref: https://anaconda.zendesk.com/agent/tickets/49522
    reason: Dependency for vllm
  recipe-maintainers:
    - ianaobi
    - bkreider

  recipe-maintainers:
    - BastianZim
